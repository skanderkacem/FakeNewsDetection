{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgZn7BfH3iGO"
   },
   "source": [
    "# 4Ô∏è‚É£ Pr√©paration des donn√©es et des repr√©sentations multimodales\n",
    "\n",
    "Encodage des textes avec BERT et extraction des features d'images avec CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izExkgCk3iGR"
   },
   "source": [
    "## üì¶ Installation et Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123315,
     "status": "ok",
     "timestamp": 1753898696113,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "D3UXHLEm3iGR",
    "outputId": "4a780003-5551-411a-dcd4-1f99aaaf875a"
   },
   "outputs": [],
   "source": [
    "# Installation des packages n√©cessaires\n",
    "!pip install torch torchvision transformers pandas numpy matplotlib seaborn\n",
    "!pip install scikit-learn requests pillow tqdm\n",
    "!pip install datasets accelerate tensorboard gradio\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18, resnet50\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Transformers pour BERT\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "\n",
    "# Sklearn pour les m√©triques\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, roc_curve\n",
    "\n",
    "# Autres imports\n",
    "from PIL import Image\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üî• Device utilis√©: {device}\")\n",
    "print(f\"üî• CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üî• GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NiMIUIOKjXlM"
   },
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import files\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69644,
     "status": "ok",
     "timestamp": 1753898765769,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "_P-5Kdn1546V",
    "outputId": "b777a193-a5d8-48a8-84d6-5336598fba63"
   },
   "outputs": [],
   "source": [
    "# Monte ton Google Drive dans Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# Remplace les chemins par les bons si besoin\n",
    "!cp \"/content/drive/MyDrive/Colab Notebooks/image_final_ancien.zip\" /content/\n",
    "!cp \"/content/drive/MyDrive/Colab Notebooks/df_multimodal_equilibre.csv\" /content/\n",
    "# Extrait le zip\n",
    "!unzip -q /content/image_final_ancien.zip -d /content/\n",
    "# V√©rification\n",
    "print(\"CSV pr√©sent :\", os.path.exists(\"/content/df_multimodal_equilibre.csv\"))\n",
    "print(\"Dossier images pr√©sent :\", os.path.exists(\"/content/image_final_ancien\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ck9x_KPr3iGT"
   },
   "source": [
    "# üìä 4.1. PR√âPARATION DES DONN√âES POUR LA MOD√âLISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1753898765813,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "pWCbgX5J3iGT",
    "outputId": "c57b12c7-62bb-4df1-d5a4-b93ebcee7dda"
   },
   "outputs": [],
   "source": [
    "print(\"üìä √âTAPE 1: PR√âPARATION DES DONN√âES POUR LA MOD√âLISATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Charger le dataset √©quilibr√©\n",
    "df = pd.read_csv('df_multimodal_equilibre.csv')\n",
    "print(f\"‚úÖ Dataset charg√©: {len(df)} articles\")\n",
    "print(f\"üìä R√©partition des labels:\\n{df['label'].value_counts()}\")\n",
    "\n",
    "# V√©rifier la structure des donn√©es\n",
    "print(f\"\\nüìã Colonnes disponibles: {list(df.columns)}\")\n",
    "print(f\"üñºÔ∏è Articles avec images: {df['has_image'].sum()}\")\n",
    "print(f\"üìÑ Articles avec texte: {df['has_text'].sum()}\")\n",
    "print(f\"üîó Articles multimodaux: {len(df[(df['has_text'] == 1) & (df['has_image'] == 1)])}\")\n",
    "\n",
    "# Affichage des statistiques d√©taill√©es par modalit√©\n",
    "modality_stats = {\n",
    "    'title_only': len(df[(df['has_text'] == 0) & (df['has_image'] == 0)]),\n",
    "    'title_text': len(df[(df['has_text'] == 1) & (df['has_image'] == 0)]),\n",
    "    'title_image': len(df[(df['has_text'] == 0) & (df['has_image'] == 1)]),\n",
    "    'multimodal': len(df[(df['has_text'] == 1) & (df['has_image'] == 1)])\n",
    "}\n",
    "\n",
    "print(f\"\\nüìä R√©partition par modalit√©:\")\n",
    "for modality, count in modality_stats.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"   - {modality}: {count} articles ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266,
     "referenced_widgets": [
      "3c1413c34929441789175b5bc888f69d",
      "f7870c242e4c4ddca92e45d4a8b6b297",
      "3c9268dc81db4fa8a9ee6250f2bc8c14",
      "b73097d400f24d5c9406cd8316716701",
      "3a72c92ef5694cf6b97e96a37d2bd11c",
      "6b27fedfbc874a5bad72e0eda7c6e8d0",
      "2251ecdf110740adb0e98af565c64083",
      "8f042b5d32e94e90baf9ff3b1c17a9e8",
      "60da816b662d459c9bd52c801c332f2f",
      "36950316f51f4b9ea0417ca80b95a6f5",
      "6884f31f879346279b4baeb597670f30",
      "ab70121018bd4379b13047c06922fc0d",
      "38d120d9e7194c39917a94b2a0e3a176",
      "11ab47d8c8524aadafb078b95df3f9ee",
      "c4d9f6fbb94b435cad73999f9cca7c3e",
      "561e5f88137e4e4696d0028b0f8efd6c",
      "d462fc8ffceb485facd712dbe698355c",
      "d6cb625a13c044c486319ce7a8218324",
      "d553fb04560d4937a33a476d5705b72e",
      "2f5b03ce5c27445496f79304b17ae619",
      "890f6a05630a4993bedd482fcd1485a5",
      "3b05b1e1083242b69cfac687bc1a0970",
      "efa9d4c743db4c2993d3ba7b279f1031",
      "20993304313b4b7290e1171b3f0aa13f",
      "e9b171a600d94c2d9d5fd942502bf0d3",
      "081c2d617a6c4f048d2178e24543249a",
      "d31db83e6a074616b9ab66540397b579",
      "e9cd3126fbe14d12884ce65cbcd7b6fa",
      "3b831a290d2044ef99b4e3ffef6f3e3e",
      "3747b4a8d0a441488a346ed8cbc6146b",
      "042363bbd33c408cabe77f595fcdf596",
      "f9042b3a1a534489bac8a8395b7ca48b",
      "2ce9847dba8949b18a11953988f38b9a",
      "43681527d5fc4e02b198dc7fbcf7bf44",
      "aa587256edde49d2a3f6899afa6b3f67",
      "1a306c1ce9b14b26b51a01a4aba3e0b9",
      "b1382d591ad044c49e0a02ab649bc13a",
      "7777baea9aff49ebb205bd6eecabae0f",
      "42e682078479493b9a1711d2620055c9",
      "c3fd7c2dfda6458d8bdf9c6c3f7e620e",
      "741d4e2ea9c24b2e9bdb6b82c971c951",
      "475a8af1470749f788dd39afdedd765f",
      "30ed4681d82448ff8dfb524e4af8bc91",
      "84ff5c3f340f495284f036f7a5ece6fd"
     ]
    },
    "executionInfo": {
     "elapsed": 2594,
     "status": "ok",
     "timestamp": 1753898780322,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "PpSaDc203iGT",
    "outputId": "dcce6b9b-53a8-4a68-bd6e-87171ce4146d"
   },
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    \"\"\"Dataset personnalis√© pour g√©rer les donn√©es multimodales\"\"\"\n",
    "    def __init__(self, dataframe, tokenizer, max_length=512, image_transform=None, images_folder='image_final_ancien'):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.image_transform = image_transform\n",
    "        self.images_folder = images_folder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Pr√©paration du texte\n",
    "        title = str(row['title']) if pd.notna(row['title']) else \"\"\n",
    "        text = str(row['text']) if pd.notna(row['text']) and row['has_text'] == 1 else \"\"\n",
    "\n",
    "        combined_text = f\"{title} [SEP] {text}\" if text else title\n",
    "\n",
    "        # Tokenisation\n",
    "        encoding = self.tokenizer(\n",
    "            combined_text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # Pr√©paration de l'image\n",
    "        image_tensor = torch.zeros(3, 224, 224)\n",
    "        has_valid_image = False\n",
    "\n",
    "        if row['has_image'] == 1 and pd.notna(row['image_path']):\n",
    "            try:\n",
    "                if os.path.exists(row['image_path']):\n",
    "                    image = Image.open(row['image_path']).convert('RGB')\n",
    "                    if self.image_transform:\n",
    "                        image_tensor = self.image_transform(image)\n",
    "                    has_valid_image = True\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Erreur chargement image {idx}: {e}\")\n",
    "\n",
    "        # Type de modalit√©\n",
    "        modality_type = self._get_modality_type(row['has_text'], has_valid_image)\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'image': image_tensor,\n",
    "            'label': torch.tensor(row['label'], dtype=torch.long),\n",
    "            'has_text': torch.tensor(row['has_text'], dtype=torch.float),\n",
    "            'has_image': torch.tensor(int(has_valid_image), dtype=torch.float),\n",
    "            'modality_type': modality_type\n",
    "        }\n",
    "\n",
    "    def _get_modality_type(self, has_text, has_image):\n",
    "        if has_text and has_image:\n",
    "            return 3  # Multimodal\n",
    "        elif has_text:\n",
    "            return 2  # Titre + Texte\n",
    "        elif has_image:\n",
    "            return 1  # Titre + Image\n",
    "        else:\n",
    "            return 0  # Titre seul\n",
    "\n",
    "# Configuration\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "print(\"‚úÖ Tokenizer BERT initialis√©\")\n",
    "\n",
    "# Division des donn√©es\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['label'])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['label'])\n",
    "\n",
    "print(f\"\\nüìä Division des donn√©es:\")\n",
    "print(f\"   - Train: {len(train_df)} articles\")\n",
    "print(f\"   - Validation: {len(val_df)} articles\")\n",
    "print(f\"   - Test: {len(test_df)} articles\")\n",
    "\n",
    "# Cr√©ation des datasets et DataLoaders\n",
    "train_dataset = MultimodalDataset(train_df, tokenizer, image_transform=image_transform)\n",
    "val_dataset = MultimodalDataset(val_df, tokenizer, image_transform=image_transform)\n",
    "test_dataset = MultimodalDataset(test_df, tokenizer, image_transform=image_transform)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(\"‚úÖ DataLoaders cr√©√©s avec succ√®s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cZwM1_P3iGU"
   },
   "source": [
    "# üèóÔ∏è 4.2. ARCHITECTURE DU MOD√àLE MULTIMODAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "09118e8cbf9441faa8ea3be40037a6f2",
      "78558cb956734bfb99ea5ad1f7d55fe3",
      "17a721885caf4686b1892cb5ae6fd7a6",
      "905249ec89e742948a782d554ab64223",
      "ebaeda5b3353491ab779f1388623752f",
      "8963fb372aab4004a25dae9b5e204fe5",
      "3b147e20c41e44ffb88297f1d9107979",
      "a95a4ee63dba430d93ca70e2741db38f",
      "13d764802c90432aa005fff606b8f65d",
      "cf43000237064285a4671671e877f0e3",
      "719415d2ed9947b5a62ecf6d40e9c5fe"
     ]
    },
    "executionInfo": {
     "elapsed": 31956,
     "status": "ok",
     "timestamp": 1753898815253,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "hmyRbXin3iGU",
    "outputId": "4b656965-d607-452c-dd28-fdf8ab170318"
   },
   "outputs": [],
   "source": [
    "class MultimodalFakeNewsDetector(nn.Module):\n",
    "    \"\"\"Mod√®le multimodal pour la d√©tection de fausses nouvelles\"\"\"\n",
    "    def __init__(self, bert_model_name='bert-base-uncased', num_classes=2, dropout_rate=0.3):\n",
    "        super(MultimodalFakeNewsDetector, self).__init__()\n",
    "\n",
    "        # Composant textuel (BERT)\n",
    "        self.bert = AutoModel.from_pretrained(bert_model_name)\n",
    "        self.bert_hidden_size = self.bert.config.hidden_size\n",
    "\n",
    "        # Composant visuel (ResNet)\n",
    "        self.resnet = resnet18(pretrained=True)\n",
    "        self.resnet_features = 512\n",
    "        self.resnet.fc = nn.Identity()\n",
    "\n",
    "        # Couches de projection\n",
    "        self.text_projection = nn.Linear(self.bert_hidden_size, 256)\n",
    "        self.image_projection = nn.Linear(self.resnet_features, 256)\n",
    "\n",
    "        # Couches de fusion multimodale\n",
    "        self.fusion_layer = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        # T√™tes de classification sp√©cialis√©es\n",
    "        self.text_only_head = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "        self.image_only_head = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "        self.multimodal_head = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "        # Couche de confiance\n",
    "        self.confidence_layer = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.text_to_confidence = nn.Linear(256, 128)\n",
    "        self.image_to_confidence = nn.Linear(256, 128)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, image, has_text, has_image, return_confidence=False):\n",
    "        batch_size = input_ids.size(0)\n",
    "\n",
    "        # Extraction des caract√©ristiques\n",
    "        text_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_features = text_outputs.pooler_output\n",
    "        text_projected = self.text_projection(text_features)\n",
    "\n",
    "        image_features = self.resnet(image)\n",
    "        image_projected = self.image_projection(image_features)\n",
    "\n",
    "        # Pr√©diction adaptative\n",
    "        predictions = []\n",
    "        confidences = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            has_text_i = has_text[i].item()\n",
    "            has_image_i = has_image[i].item()\n",
    "\n",
    "            if has_text_i and has_image_i:\n",
    "                # Multimodal\n",
    "                fused_features = torch.cat([text_projected[i:i+1], image_projected[i:i+1]], dim=1)\n",
    "                fused_output = self.fusion_layer(fused_features)\n",
    "                pred = self.multimodal_head(fused_output)\n",
    "                base_confidence = 0.90\n",
    "\n",
    "            elif has_text_i:\n",
    "                # Texte seulement\n",
    "                pred = self.text_only_head(text_projected[i:i+1])\n",
    "                fused_output = self.text_to_confidence(text_projected[i:i+1])\n",
    "                base_confidence = 0.85\n",
    "\n",
    "            elif has_image_i:\n",
    "                # Image seulement\n",
    "                pred = self.image_only_head(image_projected[i:i+1])\n",
    "                fused_output = self.image_to_confidence(image_projected[i:i+1])\n",
    "                base_confidence = 0.85\n",
    "\n",
    "            else:\n",
    "                # Titre seul\n",
    "                pred = self.text_only_head(text_projected[i:i+1])\n",
    "                fused_output = self.text_to_confidence(text_projected[i:i+1])\n",
    "                base_confidence = 0.75\n",
    "\n",
    "            predictions.append(pred)\n",
    "\n",
    "            if return_confidence:\n",
    "                dynamic_confidence = self.confidence_layer(fused_output).item()\n",
    "                final_confidence = base_confidence * dynamic_confidence\n",
    "                confidences.append(final_confidence)\n",
    "\n",
    "        predictions = torch.cat(predictions, dim=0)\n",
    "\n",
    "        if return_confidence:\n",
    "            return predictions, confidences\n",
    "        return predictions\n",
    "\n",
    "# Initialisation du mod√®le\n",
    "model = MultimodalFakeNewsDetector().to(device)\n",
    "print(\"‚úÖ Mod√®le multimodal initialis√©\")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"üìä Param√®tres totaux: {total_params:,}\")\n",
    "print(f\"üìä Param√®tres entra√Ænables: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCArkYZd3iGV"
   },
   "source": [
    "# üöÄ 4.3. ENTRA√éNEMENT DU MOD√àLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1753898815287,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "SZSt-Dn83iGV",
    "outputId": "940efa1d-b250-480e-9dcb-99d300f87c89"
   },
   "outputs": [],
   "source": [
    "print(\"\\nüöÄ √âTAPE 3: ENTRA√éNEMENT DU MOD√àLE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    'epochs': 10,\n",
    "    'learning_rate': 2e-5,\n",
    "    'weight_decay': 0.01,\n",
    "    'warmup_steps': 100,\n",
    "    'patience': 3,\n",
    "    'save_dir': 'checkpoints',\n",
    "    'best_model_path': 'best_multimodal_model.pth'\n",
    "}\n",
    "\n",
    "os.makedirs(config['save_dir'], exist_ok=True)\n",
    "\n",
    "# Optimiseur et scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "total_steps = len(train_loader) * config['epochs']\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=config['warmup_steps'],\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Variables de suivi\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "best_val_accuracy = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, scheduler, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=\"Entra√Ænement\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        images = batch['image'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        has_text = batch['has_text'].to(device)\n",
    "        has_image = batch['has_image'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask, images, has_text, has_image)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Acc': f'{100 * correct_predictions / total_predictions:.2f}%'\n",
    "        })\n",
    "\n",
    "    return total_loss / len(train_loader), correct_predictions / total_predictions\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            has_text = batch['has_text'].to(device)\n",
    "            has_image = batch['has_image'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, images, has_text, has_image)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    return total_loss / len(val_loader), correct_predictions / total_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1456011,
     "status": "ok",
     "timestamp": 1753900320204,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "rzX2WjZ43iGW",
    "outputId": "8bcc750a-ea05-472d-e416-2c9a8248d986"
   },
   "outputs": [],
   "source": [
    "# Boucle d'entra√Ænement\n",
    "print(f\"üöÄ D√©but de l'entra√Ænement pour {config['epochs']} √©poques\")\n",
    "start_time = datetime.now()\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    print(f\"\\nüìÖ √âpoque {epoch + 1}/{config['epochs']}\")\n",
    "\n",
    "    # Entra√Ænement et validation\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, scheduler, criterion, device)\n",
    "    val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "\n",
    "    # Sauvegarde des m√©triques\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"üìä Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"üìä Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Sauvegarde du meilleur mod√®le\n",
    "    if val_acc > best_val_accuracy:\n",
    "        best_val_accuracy = val_acc\n",
    "        patience_counter = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_accuracy': val_acc,\n",
    "            'config': config\n",
    "        }, config['best_model_path'])\n",
    "        print(f\"üíæ Nouveau meilleur mod√®le sauvegard√©: {config['best_model_path']}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    # Early stopping\n",
    "    if patience_counter >= config['patience']:\n",
    "        print(f\"üõë Early stopping apr√®s {epoch + 1} √©poques\")\n",
    "        break\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(f\"\\n‚è±Ô∏è Dur√©e d'entra√Ænement: {end_time - start_time}\")\n",
    "print(f\"üèÜ Meilleure pr√©cision: {best_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKphzLWY3iGW"
   },
   "source": [
    "# üìä 4.4. VISUALISATION ET √âVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "executionInfo": {
     "elapsed": 1181,
     "status": "ok",
     "timestamp": 1753900341855,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "HlymMgGb3iGW",
    "outputId": "d5610a23-4bd4-4553-b319-1cd87dcc62e4"
   },
   "outputs": [],
   "source": [
    "# Visualisation des courbes d'entra√Ænement\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "epochs_range = range(1, len(train_losses) + 1)\n",
    "\n",
    "# Courbes de perte\n",
    "ax1.plot(epochs_range, train_losses, 'b-', label='Train Loss', linewidth=2)\n",
    "ax1.plot(epochs_range, val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
    "ax1.set_title('√âvolution de la Perte', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('√âpoques')\n",
    "ax1.set_ylabel('Perte')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Courbes de pr√©cision\n",
    "ax2.plot(epochs_range, train_accuracies, 'b-', label='Train Accuracy', linewidth=2)\n",
    "ax2.plot(epochs_range, val_accuracies, 'r-', label='Validation Accuracy', linewidth=2)\n",
    "ax2.set_title('√âvolution de la Pr√©cision', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('√âpoques')\n",
    "ax2.set_ylabel('Pr√©cision')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Courbes d'entra√Ænement sauvegard√©es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "executionInfo": {
     "elapsed": 19264,
     "status": "ok",
     "timestamp": 1753900366796,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "SGkIaOja3iGW",
    "outputId": "48e84770-6d7e-48cc-b447-6ccb3de8f460"
   },
   "outputs": [],
   "source": [
    "# √âvaluation sur le dataset de test\n",
    "print(\"\\nüîç √âVALUATION SUR LE DATASET DE TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Charger le meilleur mod√®le\n",
    "best_checkpoint = torch.load(config['best_model_path'])\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# √âvaluation d√©taill√©e\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "all_confidences = []\n",
    "modality_stats = {0: {'correct': 0, 'total': 0}, 1: {'correct': 0, 'total': 0},\n",
    "                  2: {'correct': 0, 'total': 0}, 3: {'correct': 0, 'total': 0}}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Test\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        images = batch['image'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        has_text = batch['has_text'].to(device)\n",
    "        has_image = batch['has_image'].to(device)\n",
    "        modality_types = batch['modality_type']\n",
    "\n",
    "        outputs, confidences = model(input_ids, attention_mask, images, has_text, has_image, return_confidence=True)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_confidences.extend(confidences)\n",
    "\n",
    "        # Statistiques par modalit√©\n",
    "        for i in range(len(predicted)):\n",
    "            modality = modality_types[i].item()\n",
    "            modality_stats[modality]['total'] += 1\n",
    "            if predicted[i] == labels[i]:\n",
    "                modality_stats[modality]['correct'] += 1\n",
    "\n",
    "# M√©triques globales\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "avg_confidence = np.mean(all_confidences)\n",
    "\n",
    "print(f\"üìä R√âSULTATS FINAUX:\")\n",
    "print(f\"   - Pr√©cision: {accuracy:.4f}\")\n",
    "print(f\"   - F1-Score: {f1:.4f}\")\n",
    "print(f\"   - Confiance moyenne: {avg_confidence:.4f}\")\n",
    "\n",
    "# M√©triques par modalit√©\n",
    "modality_names = {0: 'Titre seul', 1: 'Titre + Image', 2: 'Titre + Texte', 3: 'Multimodal'}\n",
    "print(f\"\\nüìä R√âSULTATS PAR MODALIT√â:\")\n",
    "for modality, stats in modality_stats.items():\n",
    "    if stats['total'] > 0:\n",
    "        acc = stats['correct'] / stats['total']\n",
    "        print(f\"   - {modality_names[modality]}: {acc:.4f} ({stats['correct']}/{stats['total']})\")\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Fake News', 'Real News'],\n",
    "            yticklabels=['Fake News', 'Real News'])\n",
    "plt.title('Matrice de Confusion', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Pr√©dictions')\n",
    "plt.ylabel('Vraies √âtiquettes')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ √âvaluation termin√©e et r√©sultats sauvegard√©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7M-OWsk3iGW"
   },
   "source": [
    "# üéØ 4.5. INTERFACE DE PR√âDICTION EN TEMPS R√âEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75,
     "status": "ok",
     "timestamp": 1753900380767,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "kg85LBLp3iGX",
    "outputId": "6677af21-82c1-41e5-b83e-014c04bee876"
   },
   "outputs": [],
   "source": [
    "class FakeNewsPredictor:\n",
    "    \"\"\"Classe pour les pr√©dictions en temps r√©el\"\"\"\n",
    "\n",
    "    def __init__(self, model, tokenizer, image_transform, device):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.image_transform = image_transform\n",
    "        self.device = device\n",
    "        self.model.eval()\n",
    "\n",
    "        self.label_mapping = {0: \"Fake News\", 1: \"Real News\"}\n",
    "        self.confidence_levels = {\n",
    "            0: \"Faible (70-80%)\",\n",
    "            1: \"Moyenne (80-90%)\",\n",
    "            2: \"Moyenne (80-90%)\",\n",
    "            3: \"√âlev√©e (90%+)\"\n",
    "        }\n",
    "\n",
    "    def predict(self, title, text=\"\", image_path=None):\n",
    "        \"\"\"Pr√©diction sur un article\"\"\"\n",
    "        # Pr√©paration du texte\n",
    "        has_text = 1 if text and len(text.strip()) >= 50 else 0\n",
    "        combined_text = f\"{title} [SEP] {text}\" if has_text else title\n",
    "\n",
    "        # Tokenisation\n",
    "        encoding = self.tokenizer(\n",
    "            combined_text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # Pr√©paration de l'image\n",
    "        image_tensor = torch.zeros(1, 3, 224, 224)\n",
    "        has_image = 0\n",
    "\n",
    "        if image_path and os.path.exists(image_path):\n",
    "            try:\n",
    "                image = Image.open(image_path).convert('RGB')\n",
    "                image_tensor = self.image_transform(image).unsqueeze(0)\n",
    "                has_image = 1\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur chargement image: {e}\")\n",
    "\n",
    "        # D√©placement vers GPU\n",
    "        input_ids = encoding['input_ids'].to(self.device)\n",
    "        attention_mask = encoding['attention_mask'].to(self.device)\n",
    "        image_tensor = image_tensor.to(self.device)\n",
    "        has_text_tensor = torch.tensor([has_text], dtype=torch.float).to(self.device)\n",
    "        has_image_tensor = torch.tensor([has_image], dtype=torch.float).to(self.device)\n",
    "\n",
    "        # Pr√©diction\n",
    "        with torch.no_grad():\n",
    "            outputs, confidences = self.model(\n",
    "                input_ids, attention_mask, image_tensor,\n",
    "                has_text_tensor, has_image_tensor,\n",
    "                return_confidence=True\n",
    "            )\n",
    "\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            prediction = predicted.item()\n",
    "            confidence = confidences[0]\n",
    "            prob_fake = probabilities[0][0].item()\n",
    "            prob_real = probabilities[0][1].item()\n",
    "\n",
    "        # D√©termination du type de modalit√©\n",
    "        if has_text and has_image:\n",
    "            modality_type = 3\n",
    "        elif has_text:\n",
    "            modality_type = 2\n",
    "        elif has_image:\n",
    "            modality_type = 1\n",
    "        else:\n",
    "            modality_type = 0\n",
    "\n",
    "        return {\n",
    "            'prediction': self.label_mapping[prediction],\n",
    "            'confidence': confidence,\n",
    "            'confidence_level': self.confidence_levels[modality_type],\n",
    "            'probabilities': {\n",
    "                'fake': prob_fake,\n",
    "                'real': prob_real\n",
    "            },\n",
    "            'modality_type': modality_type,\n",
    "            'has_text': bool(has_text),\n",
    "            'has_image': bool(has_image)\n",
    "        }\n",
    "\n",
    "# Initialisation du pr√©dicteur\n",
    "predictor = FakeNewsPredictor(model, tokenizer, image_transform, device)\n",
    "print(\"‚úÖ Pr√©dicteur initialis√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 474,
     "status": "ok",
     "timestamp": 1753900393147,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "gRlSDlYLf0DS",
    "outputId": "0f86474a-e267-4f0c-8fb3-0c1e8a222fed"
   },
   "outputs": [],
   "source": [
    "def test_prediction():\n",
    "    print(\"\\nüéØ TESTS MULTIMODALIT√âS\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # ========= TITRE SEUL =========\n",
    "    print(\"\\nüü© TITRE SEUL\")\n",
    "    examples_title_only = [\n",
    "        \"Aliens seen landing on the White House lawn\",\n",
    "        \"Global economy shows strong recovery signs\"\n",
    "    ]\n",
    "    for i, title in enumerate(examples_title_only, 1):\n",
    "        result = predictor.predict(title)\n",
    "        print(f\"\\nüîπ Exemple {i}\")\n",
    "        print(f\"   Titre: {title}\")\n",
    "        print(f\"   Pr√©diction: {result['prediction']} | Confiance: {result['confidence']:.3f} ({result['confidence_level']})\")\n",
    "        print(f\"   ‚û§ Probabilit√©s: Fake={result['probabilities']['fake']:.3f}, Real={result['probabilities']['real']:.3f}\")\n",
    "\n",
    "    # ========= TITRE + TEXTE =========\n",
    "    print(\"\\nüü® TITRE + TEXTE\")\n",
    "    examples_title_text = [\n",
    "        (\n",
    "            \"Vaccine proves 100% effective in new trial\",\n",
    "            \"A new trial conducted in Germany has proven that the vaccine is 100% effective across all age groups.\"\n",
    "        ),\n",
    "        (\n",
    "            \"NASA to build base on the moon by 2030\",\n",
    "            \"NASA announced plans to build a permanent research station on the moon within the next decade.\"\n",
    "        )\n",
    "    ]\n",
    "    for i, (title, text) in enumerate(examples_title_text, 1):\n",
    "        result = predictor.predict(title, text)\n",
    "        print(f\"\\nüîπ Exemple {i}\")\n",
    "        print(f\"   Titre: {title}\")\n",
    "        print(f\"   Texte: {text[:100]}...\")\n",
    "        print(f\"   Pr√©diction: {result['prediction']} | Confiance: {result['confidence']:.3f} ({result['confidence_level']})\")\n",
    "        print(f\"   ‚û§ Probabilit√©s: Fake={result['probabilities']['fake']:.3f}, Real={result['probabilities']['real']:.3f}\")\n",
    "\n",
    "    # ========= TITRE + IMAGE =========\n",
    "    print(\"\\nüü¶ TITRE + IMAGE\")\n",
    "    examples_title_image = [\n",
    "        (\n",
    "            \"President caught doing something shocking\",\n",
    "            \"/content/image_final_ancien/ebb2b165f3ba33aabebaf416a7f2bb4b.jpg\"\n",
    "        ),\n",
    "        (\n",
    "            \"World Cup final ends in dramatic fashion\",\n",
    "            \"/content/image_final_ancien/f52a1871a7bd2e1de6b5f87be65a3ad6.jpg\"\n",
    "        )\n",
    "    ]\n",
    "    for i, (title, img_path) in enumerate(examples_title_image, 1):\n",
    "        result = predictor.predict(title, image_path=img_path)\n",
    "        print(f\"\\nüîπ Exemple {i}\")\n",
    "        print(f\"   Titre: {title}\")\n",
    "        print(f\"   Image: {img_path}\")\n",
    "        print(f\"   Pr√©diction: {result['prediction']} | Confiance: {result['confidence']:.3f} ({result['confidence_level']})\")\n",
    "        print(f\"   ‚û§ Probabilit√©s: Fake={result['probabilities']['fake']:.3f}, Real={result['probabilities']['real']:.3f}\")\n",
    "\n",
    "    # ========= TITRE + TEXTE + IMAGE =========\n",
    "    print(\"\\nüü• TITRE + TEXTE + IMAGE\")\n",
    "    examples_full = [\n",
    "        (\n",
    "            \"Anti-Trump Super PAC Launches Pre-Debate Video Featuring Hofstra Students\",\n",
    "            \"An anti-Donald Trump super PAC is going on the offensive ahead of the first presidential debate...\",\n",
    "            \"/content/image_final_ancien/ebb2b165f3ba33aabebaf416a7f2bb4b.jpg\"\n",
    "        ),\n",
    "        (\n",
    "            \"Scientists celebrate successful Mars landing\",\n",
    "            \"NASA scientists cheered as the latest Mars lander touched down safely, confirming decades of planning.\",\n",
    "            \"/content/image_final_ancien/f52a1871a7bd2e1de6b5f87be65a3ad6.jpg\"\n",
    "        )\n",
    "    ]\n",
    "    for i, (title, text, img_path) in enumerate(examples_full, 1):\n",
    "        result = predictor.predict(title, text, img_path)\n",
    "        print(f\"\\nüîπ Exemple {i}\")\n",
    "        print(f\"   Titre: {title}\")\n",
    "        print(f\"   Texte: {text[:100]}...\")\n",
    "        print(f\"   Image: {img_path}\")\n",
    "        print(f\"   Pr√©diction: {result['prediction']} | Confiance: {result['confidence']:.3f} ({result['confidence_level']})\")\n",
    "        print(f\"   ‚û§ Probabilit√©s: Fake={result['probabilities']['fake']:.3f}, Real={result['probabilities']['real']:.3f}\")\n",
    "\n",
    "    print(\"\\n‚úÖ Tous les tests de pr√©diction sont termin√©s.\")\n",
    "\n",
    "# ‚ñ∂Ô∏è Appel de la fonction\n",
    "test_prediction()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmZFzSbM3iGX"
   },
   "source": [
    "# üíæ 4.6. SAUVEGARDE ET EXPORT DU MOD√àLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1753900440580,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "stdeSP5T3iGX",
    "outputId": "80113490-ee98-4410-ca97-5bf88af9bbed"
   },
   "outputs": [],
   "source": [
    "print(\"\\nüíæ SAUVEGARDE ET EXPORT DU MOD√àLE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Sauvegarde des r√©sultats finaux\n",
    "final_results = {\n",
    "    'model_info': {\n",
    "        'architecture': 'MultimodalFakeNewsDetector',\n",
    "        'bert_model': 'bert-base-uncased',\n",
    "        'cnn_model': 'resnet18',\n",
    "        'total_parameters': total_params,\n",
    "        'trainable_parameters': trainable_params\n",
    "    },\n",
    "    'training_config': config,\n",
    "    'final_metrics': {\n",
    "        'test_accuracy': float(accuracy),\n",
    "        'test_f1_score': float(f1),\n",
    "        'average_confidence': float(avg_confidence),\n",
    "        'best_val_accuracy': float(best_val_accuracy)\n",
    "    },\n",
    "    'modality_performance': {},\n",
    "    'training_history': {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies\n",
    "    }\n",
    "}\n",
    "\n",
    "# Ajouter les performances par modalit√©\n",
    "for modality, stats in modality_stats.items():\n",
    "    if stats['total'] > 0:\n",
    "        final_results['modality_performance'][modality_names[modality]] = {\n",
    "            'accuracy': float(stats['correct'] / stats['total']),\n",
    "            'samples': stats['total']\n",
    "        }\n",
    "\n",
    "# Sauvegarde JSON\n",
    "with open('final_results.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "\n",
    "# Sauvegarde du tokenizer\n",
    "tokenizer.save_pretrained('saved_tokenizer')\n",
    "\n",
    "# Sauvegarde des transformations d'images\n",
    "with open('image_transform.pkl', 'wb') as f:\n",
    "    pickle.dump(image_transform, f)\n",
    "\n",
    "print(\"‚úÖ R√©sultats finaux sauvegard√©s: final_results.json\")\n",
    "print(\"‚úÖ Tokenizer sauvegard√©: saved_tokenizer/\")\n",
    "print(\"‚úÖ Transformations d'images sauvegard√©es: image_transform.pkl\")\n",
    "print(f\"‚úÖ Meilleur mod√®le disponible: {config['best_model_path']}\")\n",
    "\n",
    "print(f\"\\nüéâ PIPELINE DE MOD√âLISATION TERMIN√â AVEC SUCC√àS!\")\n",
    "print(f\"üìä Pr√©cision finale: {accuracy:.4f}\")\n",
    "print(f\"üìä F1-Score: {f1:.4f}\")\n",
    "print(f\"üìä Confiance moyenne: {avg_confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "executionInfo": {
     "elapsed": 156,
     "status": "ok",
     "timestamp": 1753900450912,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "-spXuipfjHOR",
    "outputId": "446a621c-3f7d-4d39-c133-fee2fa0a509a"
   },
   "outputs": [],
   "source": [
    "print(\"\\nüíæ SAUVEGARDE ET EXPORT DU MOD√àLE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Sauvegarde des r√©sultats finaux\n",
    "final_results = {\n",
    "    'model_info': {\n",
    "        'architecture': 'MultimodalFakeNewsDetector',\n",
    "        'bert_model': 'bert-base-uncased',\n",
    "        'cnn_model': 'resnet18',\n",
    "        'total_parameters': total_params,\n",
    "        'trainable_parameters': trainable_params\n",
    "    },\n",
    "    'training_config': config,\n",
    "    'final_metrics': {\n",
    "        'test_accuracy': float(accuracy),\n",
    "        'test_f1_score': float(f1),\n",
    "        'average_confidence': float(avg_confidence),\n",
    "        'best_val_accuracy': float(best_val_accuracy)\n",
    "    },\n",
    "    'modality_performance': {},\n",
    "    'training_history': {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies\n",
    "    }\n",
    "}\n",
    "\n",
    "# Ajouter les performances par modalit√©\n",
    "for modality, stats in modality_stats.items():\n",
    "    if stats['total'] > 0:\n",
    "        final_results['modality_performance'][modality_names[modality]] = {\n",
    "            'accuracy': float(stats['correct'] / stats['total']),\n",
    "            'samples': stats['total']\n",
    "        }\n",
    "\n",
    "# Sauvegarde JSON\n",
    "with open('final_results.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "\n",
    "# Sauvegarde du tokenizer\n",
    "tokenizer.save_pretrained('saved_tokenizer')\n",
    "\n",
    "# Sauvegarde des transformations d'images\n",
    "with open('image_transform.pkl', 'wb') as f:\n",
    "    pickle.dump(image_transform, f)\n",
    "\n",
    "print(\"‚úÖ R√©sultats finaux sauvegard√©s: final_results.json\")\n",
    "print(\"‚úÖ Tokenizer sauvegard√©: saved_tokenizer/\")\n",
    "print(\"‚úÖ Transformations d'images sauvegard√©es: image_transform.pkl\")\n",
    "print(f\"‚úÖ Meilleur mod√®le disponible: {config['best_model_path']}\")\n",
    "\n",
    "# üì¶ Compression du tokenizer en .zip pour t√©l√©chargement\n",
    "!zip -rq saved_tokenizer.zip saved_tokenizer\n",
    "\n",
    "# üíæ T√©l√©chargement des fichiers vers le PC\n",
    "files.download(\"final_results.json\")\n",
    "files.download(\"image_transform.pkl\")\n",
    "files.download(\"saved_tokenizer.zip\")\n",
    "files.download(config[\"best_model_path\"])  # \"best_multimodal_model.pth\"\n",
    "\n",
    "print(f\"\\nüéâ PIPELINE DE MOD√âLISATION TERMIN√â AVEC SUCC√àS!\")\n",
    "print(f\"üìä Pr√©cision finale: {accuracy:.4f}\")\n",
    "print(f\"üìä F1-Score: {f1:.4f}\")\n",
    "print(f\"üìä Confiance moyenne: {avg_confidence:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1753901183427,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "SOD3WZcPp2_5",
    "outputId": "0abce508-cd00-4ce0-c0a2-2eb4f5495242"
   },
   "outputs": [],
   "source": [
    "files.download(config[\"best_model_path\"])  # \"best_multimodal_model.pth\"\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1QgH9-JGvUDANYpRfxPr0Bn4IdrgoU670",
     "timestamp": 1754499596452
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
