{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgZn7BfH3iGO"
   },
   "source": [
    "# 4ï¸âƒ£ PrÃ©paration des donnÃ©es et des reprÃ©sentations multimodales\n",
    "\n",
    "Encodage des textes avec BERT et extraction des features d'images avec CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izExkgCk3iGR"
   },
   "source": [
    "## ðŸ“¦ Installation et Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123315,
     "status": "ok",
     "timestamp": 1753898696113,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "D3UXHLEm3iGR",
    "outputId": "4a780003-5551-411a-dcd4-1f99aaaf875a"
   },
   "outputs": [],
   "source": [
    "# Installation des packages nÃ©cessaires\n",
    "!pip install torch torchvision transformers pandas numpy matplotlib seaborn\n",
    "!pip install scikit-learn requests pillow tqdm\n",
    "!pip install datasets accelerate tensorboard gradio\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18, resnet50\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Transformers pour BERT\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "\n",
    "# Sklearn pour les mÃ©triques\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, roc_curve\n",
    "\n",
    "# Autres imports\n",
    "from PIL import Image\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸ”¥ Device utilisÃ©: {device}\")\n",
    "print(f\"ðŸ”¥ CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"ðŸ”¥ GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NiMIUIOKjXlM"
   },
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import files\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69644,
     "status": "ok",
     "timestamp": 1753898765769,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "_P-5Kdn1546V",
    "outputId": "b777a193-a5d8-48a8-84d6-5336598fba63"
   },
   "outputs": [],
   "source": [
    "# Monte ton Google Drive dans Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# Remplace les chemins par les bons si besoin\n",
    "!cp \"/content/drive/MyDrive/Colab Notebooks/image_final_ancien.zip\" /content/\n",
    "!cp \"/content/drive/MyDrive/Colab Notebooks/df_multimodal_equilibre.csv\" /content/\n",
    "# Extrait le zip\n",
    "!unzip -q /content/image_final_ancien.zip -d /content/\n",
    "# VÃ©rification\n",
    "print(\"CSV prÃ©sent :\", os.path.exists(\"/content/df_multimodal_equilibre.csv\"))\n",
    "print(\"Dossier images prÃ©sent :\", os.path.exists(\"/content/image_final_ancien\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ck9x_KPr3iGT"
   },
   "source": [
    "# ðŸ“Š 4.1. PRÃ‰PARATION DES DONNÃ‰ES POUR LA MODÃ‰LISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1753898765813,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "pWCbgX5J3iGT",
    "outputId": "c57b12c7-62bb-4df1-d5a4-b93ebcee7dda"
   },
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š Ã‰TAPE 1: PRÃ‰PARATION DES DONNÃ‰ES POUR LA MODÃ‰LISATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Charger le dataset Ã©quilibrÃ©\n",
    "df = pd.read_csv('df_multimodal_equilibre.csv')\n",
    "print(f\"âœ… Dataset chargÃ©: {len(df)} articles\")\n",
    "print(f\"ðŸ“Š RÃ©partition des labels:\\n{df['label'].value_counts()}\")\n",
    "\n",
    "# VÃ©rifier la structure des donnÃ©es\n",
    "print(f\"\\nðŸ“‹ Colonnes disponibles: {list(df.columns)}\")\n",
    "print(f\"ðŸ–¼ï¸ Articles avec images: {df['has_image'].sum()}\")\n",
    "print(f\"ðŸ“„ Articles avec texte: {df['has_text'].sum()}\")\n",
    "print(f\"ðŸ”— Articles multimodaux: {len(df[(df['has_text'] == 1) & (df['has_image'] == 1)])}\")\n",
    "\n",
    "# Affichage des statistiques dÃ©taillÃ©es par modalitÃ©\n",
    "modality_stats = {\n",
    "    'title_only': len(df[(df['has_text'] == 0) & (df['has_image'] == 0)]),\n",
    "    'title_text': len(df[(df['has_text'] == 1) & (df['has_image'] == 0)]),\n",
    "    'title_image': len(df[(df['has_text'] == 0) & (df['has_image'] == 1)]),\n",
    "    'multimodal': len(df[(df['has_text'] == 1) & (df['has_image'] == 1)])\n",
    "}\n",
    "\n",
    "print(f\"\\nðŸ“Š RÃ©partition par modalitÃ©:\")\n",
    "for modality, count in modality_stats.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"   - {modality}: {count} articles ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266,
     "referenced_widgets": [
      "3c1413c34929441789175b5bc888f69d",
      "f7870c242e4c4ddca92e45d4a8b6b297",
      "3c9268dc81db4fa8a9ee6250f2bc8c14",
      "b73097d400f24d5c9406cd8316716701",
      "3a72c92ef5694cf6b97e96a37d2bd11c",
      "6b27fedfbc874a5bad72e0eda7c6e8d0",
      "2251ecdf110740adb0e98af565c64083",
      "8f042b5d32e94e90baf9ff3b1c17a9e8",
      "60da816b662d459c9bd52c801c332f2f",
      "36950316f51f4b9ea0417ca80b95a6f5",
      "6884f31f879346279b4baeb597670f30",
      "ab70121018bd4379b13047c06922fc0d",
      "38d120d9e7194c39917a94b2a0e3a176",
      "11ab47d8c8524aadafb078b95df3f9ee",
      "c4d9f6fbb94b435cad73999f9cca7c3e",
      "561e5f88137e4e4696d0028b0f8efd6c",
      "d462fc8ffceb485facd712dbe698355c",
      "d6cb625a13c044c486319ce7a8218324",
      "d553fb04560d4937a33a476d5705b72e",
      "2f5b03ce5c27445496f79304b17ae619",
      "890f6a05630a4993bedd482fcd1485a5",
      "3b05b1e1083242b69cfac687bc1a0970",
      "efa9d4c743db4c2993d3ba7b279f1031",
      "20993304313b4b7290e1171b3f0aa13f",
      "e9b171a600d94c2d9d5fd942502bf0d3",
      "081c2d617a6c4f048d2178e24543249a",
      "d31db83e6a074616b9ab66540397b579",
      "e9cd3126fbe14d12884ce65cbcd7b6fa",
      "3b831a290d2044ef99b4e3ffef6f3e3e",
      "3747b4a8d0a441488a346ed8cbc6146b",
      "042363bbd33c408cabe77f595fcdf596",
      "f9042b3a1a534489bac8a8395b7ca48b",
      "2ce9847dba8949b18a11953988f38b9a",
      "43681527d5fc4e02b198dc7fbcf7bf44",
      "aa587256edde49d2a3f6899afa6b3f67",
      "1a306c1ce9b14b26b51a01a4aba3e0b9",
      "b1382d591ad044c49e0a02ab649bc13a",
      "7777baea9aff49ebb205bd6eecabae0f",
      "42e682078479493b9a1711d2620055c9",
      "c3fd7c2dfda6458d8bdf9c6c3f7e620e",
      "741d4e2ea9c24b2e9bdb6b82c971c951",
      "475a8af1470749f788dd39afdedd765f",
      "30ed4681d82448ff8dfb524e4af8bc91",
      "84ff5c3f340f495284f036f7a5ece6fd"
     ]
    },
    "executionInfo": {
     "elapsed": 2594,
     "status": "ok",
     "timestamp": 1753898780322,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "PpSaDc203iGT",
    "outputId": "dcce6b9b-53a8-4a68-bd6e-87171ce4146d"
   },
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    \"\"\"Dataset personnalisÃ© pour gÃ©rer les donnÃ©es multimodales\"\"\"\n",
    "    def __init__(self, dataframe, tokenizer, max_length=512, image_transform=None, images_folder='image_final_ancien'):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.image_transform = image_transform\n",
    "        self.images_folder = images_folder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # PrÃ©paration du texte\n",
    "        title = str(row['title']) if pd.notna(row['title']) else \"\"\n",
    "        text = str(row['text']) if pd.notna(row['text']) and row['has_text'] == 1 else \"\"\n",
    "\n",
    "        combined_text = f\"{title} [SEP] {text}\" if text else title\n",
    "\n",
    "        # Tokenisation\n",
    "        encoding = self.tokenizer(\n",
    "            combined_text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # PrÃ©paration de l'image\n",
    "        image_tensor = torch.zeros(3, 224, 224)\n",
    "        has_valid_image = False\n",
    "\n",
    "        if row['has_image'] == 1 and pd.notna(row['image_path']):\n",
    "            try:\n",
    "                if os.path.exists(row['image_path']):\n",
    "                    image = Image.open(row['image_path']).convert('RGB')\n",
    "                    if self.image_transform:\n",
    "                        image_tensor = self.image_transform(image)\n",
    "                    has_valid_image = True\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Erreur chargement image {idx}: {e}\")\n",
    "\n",
    "        # Type de modalitÃ©\n",
    "        modality_type = self._get_modality_type(row['has_text'], has_valid_image)\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'image': image_tensor,\n",
    "            'label': torch.tensor(row['label'], dtype=torch.long),\n",
    "            'has_text': torch.tensor(row['has_text'], dtype=torch.float),\n",
    "            'has_image': torch.tensor(int(has_valid_image), dtype=torch.float),\n",
    "            'modality_type': modality_type\n",
    "        }\n",
    "\n",
    "    def _get_modality_type(self, has_text, has_image):\n",
    "        if has_text and has_image:\n",
    "            return 3  # Multimodal\n",
    "        elif has_text:\n",
    "            return 2  # Titre + Texte\n",
    "        elif has_image:\n",
    "            return 1  # Titre + Image\n",
    "        else:\n",
    "            return 0  # Titre seul\n",
    "\n",
    "# Configuration\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "print(\"âœ… Tokenizer BERT initialisÃ©\")\n",
    "\n",
    "# Division des donnÃ©es\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['label'])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['label'])\n",
    "\n",
    "print(f\"\\nðŸ“Š Division des donnÃ©es:\")\n",
    "print(f\"   - Train: {len(train_df)} articles\")\n",
    "print(f\"   - Validation: {len(val_df)} articles\")\n",
    "print(f\"   - Test: {len(test_df)} articles\")\n",
    "\n",
    "# CrÃ©ation des datasets et DataLoaders\n",
    "train_dataset = MultimodalDataset(train_df, tokenizer, image_transform=image_transform)\n",
    "val_dataset = MultimodalDataset(val_df, tokenizer, image_transform=image_transform)\n",
    "test_dataset = MultimodalDataset(test_df, tokenizer, image_transform=image_transform)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(\"âœ… DataLoaders crÃ©Ã©s avec succÃ¨s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cZwM1_P3iGU"
   },
   "source": [
    "# ðŸ—ï¸ 4.2. ARCHITECTURE DU MODÃˆLE MULTIMODAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "09118e8cbf9441faa8ea3be40037a6f2",
      "78558cb956734bfb99ea5ad1f7d55fe3",
      "17a721885caf4686b1892cb5ae6fd7a6",
      "905249ec89e742948a782d554ab64223",
      "ebaeda5b3353491ab779f1388623752f",
      "8963fb372aab4004a25dae9b5e204fe5",
      "3b147e20c41e44ffb88297f1d9107979",
      "a95a4ee63dba430d93ca70e2741db38f",
      "13d764802c90432aa005fff606b8f65d",
      "cf43000237064285a4671671e877f0e3",
      "719415d2ed9947b5a62ecf6d40e9c5fe"
     ]
    },
    "executionInfo": {
     "elapsed": 31956,
     "status": "ok",
     "timestamp": 1753898815253,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "hmyRbXin3iGU",
    "outputId": "4b656965-d607-452c-dd28-fdf8ab170318"
   },
   "outputs": [],
   "source": [
    "class MultimodalFakeNewsDetector(nn.Module):\n",
    "    \"\"\"ModÃ¨le multimodal pour la dÃ©tection de fausses nouvelles\"\"\"\n",
    "    def __init__(self, bert_model_name='bert-base-uncased', num_classes=2, dropout_rate=0.3):\n",
    "        super(MultimodalFakeNewsDetector, self).__init__()\n",
    "\n",
    "        # Composant textuel (BERT)\n",
    "        self.bert = AutoModel.from_pretrained(bert_model_name)\n",
    "        self.bert_hidden_size = self.bert.config.hidden_size\n",
    "\n",
    "        # Composant visuel (ResNet)\n",
    "        self.resnet = resnet18(pretrained=True)\n",
    "        self.resnet_features = 512\n",
    "        self.resnet.fc = nn.Identity()\n",
    "\n",
    "        # Couches de projection\n",
    "        self.text_projection = nn.Linear(self.bert_hidden_size, 256)\n",
    "        self.image_projection = nn.Linear(self.resnet_features, 256)\n",
    "\n",
    "        # Couches de fusion multimodale\n",
    "        self.fusion_layer = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        # TÃªtes de classification spÃ©cialisÃ©es\n",
    "        self.text_only_head = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "        self.image_only_head = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "        self.multimodal_head = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "        # Couche de confiance\n",
    "        self.confidence_layer = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.text_to_confidence = nn.Linear(256, 128)\n",
    "        self.image_to_confidence = nn.Linear(256, 128)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, image, has_text, has_image, return_confidence=False):\n",
    "        batch_size = input_ids.size(0)\n",
    "\n",
    "        # Extraction des caractÃ©ristiques\n",
    "        text_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_features = text_outputs.pooler_output\n",
    "        text_projected = self.text_projection(text_features)\n",
    "\n",
    "        image_features = self.resnet(image)\n",
    "        image_projected = self.image_projection(image_features)\n",
    "\n",
    "        # PrÃ©diction adaptative\n",
    "        predictions = []\n",
    "        confidences = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            has_text_i = has_text[i].item()\n",
    "            has_image_i = has_image[i].item()\n",
    "\n",
    "            if has_text_i and has_image_i:\n",
    "                # Multimodal\n",
    "                fused_features = torch.cat([text_projected[i:i+1], image_projected[i:i+1]], dim=1)\n",
    "                fused_output = self.fusion_layer(fused_features)\n",
    "                pred = self.multimodal_head(fused_output)\n",
    "                base_confidence = 0.90\n",
    "\n",
    "            elif has_text_i:\n",
    "                # Texte seulement\n",
    "                pred = self.text_only_head(text_projected[i:i+1])\n",
    "                fused_output = self.text_to_confidence(text_projected[i:i+1])\n",
    "                base_confidence = 0.85\n",
    "\n",
    "            elif has_image_i:\n",
    "                # Image seulement\n",
    "                pred = self.image_only_head(image_projected[i:i+1])\n",
    "                fused_output = self.image_to_confidence(image_projected[i:i+1])\n",
    "                base_confidence = 0.85\n",
    "\n",
    "            else:\n",
    "                # Titre seul\n",
    "                pred = self.text_only_head(text_projected[i:i+1])\n",
    "                fused_output = self.text_to_confidence(text_projected[i:i+1])\n",
    "                base_confidence = 0.75\n",
    "\n",
    "            predictions.append(pred)\n",
    "\n",
    "            if return_confidence:\n",
    "                dynamic_confidence = self.confidence_layer(fused_output).item()\n",
    "                final_confidence = base_confidence * dynamic_confidence\n",
    "                confidences.append(final_confidence)\n",
    "\n",
    "        predictions = torch.cat(predictions, dim=0)\n",
    "\n",
    "        if return_confidence:\n",
    "            return predictions, confidences\n",
    "        return predictions\n",
    "\n",
    "# Initialisation du modÃ¨le\n",
    "model = MultimodalFakeNewsDetector().to(device)\n",
    "print(\"âœ… ModÃ¨le multimodal initialisÃ©\")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"ðŸ“Š ParamÃ¨tres totaux: {total_params:,}\")\n",
    "print(f\"ðŸ“Š ParamÃ¨tres entraÃ®nables: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCArkYZd3iGV"
   },
   "source": [
    "# ðŸš€ 4.3. ENTRAÃŽNEMENT DU MODÃˆLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1753898815287,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "SZSt-Dn83iGV",
    "outputId": "940efa1d-b250-480e-9dcb-99d300f87c89"
   },
   "outputs": [],
   "source": [
    "print(\"\\nðŸš€ Ã‰TAPE 3: ENTRAÃŽNEMENT DU MODÃˆLE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    'epochs': 10,\n",
    "    'learning_rate': 2e-5,\n",
    "    'weight_decay': 0.01,\n",
    "    'warmup_steps': 100,\n",
    "    'patience': 3,\n",
    "    'save_dir': 'checkpoints',\n",
    "    'best_model_path': 'best_multimodal_model.pth'\n",
    "}\n",
    "\n",
    "os.makedirs(config['save_dir'], exist_ok=True)\n",
    "\n",
    "# Optimiseur et scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "total_steps = len(train_loader) * config['epochs']\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=config['warmup_steps'],\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Variables de suivi\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "best_val_accuracy = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, scheduler, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=\"EntraÃ®nement\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        images = batch['image'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        has_text = batch['has_text'].to(device)\n",
    "        has_image = batch['has_image'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask, images, has_text, has_image)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Acc': f'{100 * correct_predictions / total_predictions:.2f}%'\n",
    "        })\n",
    "\n",
    "    return total_loss / len(train_loader), correct_predictions / total_predictions\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            has_text = batch['has_text'].to(device)\n",
    "            has_image = batch['has_image'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, images, has_text, has_image)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    return total_loss / len(val_loader), correct_predictions / total_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1456011,
     "status": "ok",
     "timestamp": 1753900320204,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "rzX2WjZ43iGW",
    "outputId": "8bcc750a-ea05-472d-e416-2c9a8248d986"
   },
   "outputs": [],
   "source": [
    "# Boucle d'entraÃ®nement\n",
    "print(f\"ðŸš€ DÃ©but de l'entraÃ®nement pour {config['epochs']} Ã©poques\")\n",
    "start_time = datetime.now()\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    print(f\"\\nðŸ“… Ã‰poque {epoch + 1}/{config['epochs']}\")\n",
    "\n",
    "    # EntraÃ®nement et validation\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, scheduler, criterion, device)\n",
    "    val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "\n",
    "    # Sauvegarde des mÃ©triques\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"ðŸ“Š Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"ðŸ“Š Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Sauvegarde du meilleur modÃ¨le\n",
    "    if val_acc > best_val_accuracy:\n",
    "        best_val_accuracy = val_acc\n",
    "        patience_counter = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_accuracy': val_acc,\n",
    "            'config': config\n",
    "        }, config['best_model_path'])\n",
    "        print(f\"ðŸ’¾ Nouveau meilleur modÃ¨le sauvegardÃ©: {config['best_model_path']}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    # Early stopping\n",
    "    if patience_counter >= config['patience']:\n",
    "        print(f\"ðŸ›‘ Early stopping aprÃ¨s {epoch + 1} Ã©poques\")\n",
    "        break\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(f\"\\nâ±ï¸ DurÃ©e d'entraÃ®nement: {end_time - start_time}\")\n",
    "print(f\"ðŸ† Meilleure prÃ©cision: {best_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKphzLWY3iGW"
   },
   "source": [
    "# ðŸ“Š 4.4. VISUALISATION ET Ã‰VALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "executionInfo": {
     "elapsed": 1181,
     "status": "ok",
     "timestamp": 1753900341855,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "HlymMgGb3iGW",
    "outputId": "d5610a23-4bd4-4553-b319-1cd87dcc62e4"
   },
   "outputs": [],
   "source": [
    "# Visualisation des courbes d'entraÃ®nement\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "epochs_range = range(1, len(train_losses) + 1)\n",
    "\n",
    "# Courbes de perte\n",
    "ax1.plot(epochs_range, train_losses, 'b-', label='Train Loss', linewidth=2)\n",
    "ax1.plot(epochs_range, val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
    "ax1.set_title('Ã‰volution de la Perte', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Ã‰poques')\n",
    "ax1.set_ylabel('Perte')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Courbes de prÃ©cision\n",
    "ax2.plot(epochs_range, train_accuracies, 'b-', label='Train Accuracy', linewidth=2)\n",
    "ax2.plot(epochs_range, val_accuracies, 'r-', label='Validation Accuracy', linewidth=2)\n",
    "ax2.set_title('Ã‰volution de la PrÃ©cision', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Ã‰poques')\n",
    "ax2.set_ylabel('PrÃ©cision')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Courbes d'entraÃ®nement sauvegardÃ©es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "executionInfo": {
     "elapsed": 19264,
     "status": "ok",
     "timestamp": 1753900366796,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "SGkIaOja3iGW",
    "outputId": "48e84770-6d7e-48cc-b447-6ccb3de8f460"
   },
   "outputs": [],
   "source": [
    "# Ã‰valuation sur le dataset de test\n",
    "print(\"\\nðŸ” Ã‰VALUATION SUR LE DATASET DE TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Charger le meilleur modÃ¨le\n",
    "best_checkpoint = torch.load(config['best_model_path'])\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Ã‰valuation dÃ©taillÃ©e\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "all_confidences = []\n",
    "modality_stats = {0: {'correct': 0, 'total': 0}, 1: {'correct': 0, 'total': 0},\n",
    "                  2: {'correct': 0, 'total': 0}, 3: {'correct': 0, 'total': 0}}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Test\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        images = batch['image'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        has_text = batch['has_text'].to(device)\n",
    "        has_image = batch['has_image'].to(device)\n",
    "        modality_types = batch['modality_type']\n",
    "\n",
    "        outputs, confidences = model(input_ids, attention_mask, images, has_text, has_image, return_confidence=True)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_confidences.extend(confidences)\n",
    "\n",
    "        # Statistiques par modalitÃ©\n",
    "        for i in range(len(predicted)):\n",
    "            modality = modality_types[i].item()\n",
    "            modality_stats[modality]['total'] += 1\n",
    "            if predicted[i] == labels[i]:\n",
    "                modality_stats[modality]['correct'] += 1\n",
    "\n",
    "# MÃ©triques globales\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "avg_confidence = np.mean(all_confidences)\n",
    "\n",
    "print(f\"ðŸ“Š RÃ‰SULTATS FINAUX:\")\n",
    "print(f\"   - PrÃ©cision: {accuracy:.4f}\")\n",
    "print(f\"   - F1-Score: {f1:.4f}\")\n",
    "print(f\"   - Confiance moyenne: {avg_confidence:.4f}\")\n",
    "\n",
    "# MÃ©triques par modalitÃ©\n",
    "modality_names = {0: 'Titre seul', 1: 'Titre + Image', 2: 'Titre + Texte', 3: 'Multimodal'}\n",
    "print(f\"\\nðŸ“Š RÃ‰SULTATS PAR MODALITÃ‰:\")\n",
    "for modality, stats in modality_stats.items():\n",
    "    if stats['total'] > 0:\n",
    "        acc = stats['correct'] / stats['total']\n",
    "        print(f\"   - {modality_names[modality]}: {acc:.4f} ({stats['correct']}/{stats['total']})\")\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Fake News', 'Real News'],\n",
    "            yticklabels=['Fake News', 'Real News'])\n",
    "plt.title('Matrice de Confusion', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('PrÃ©dictions')\n",
    "plt.ylabel('Vraies Ã‰tiquettes')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Ã‰valuation terminÃ©e et rÃ©sultats sauvegardÃ©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7M-OWsk3iGW"
   },
   "source": [
    "# ðŸŽ¯ 4.5. INTERFACE DE PRÃ‰DICTION EN TEMPS RÃ‰EL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75,
     "status": "ok",
     "timestamp": 1753900380767,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "kg85LBLp3iGX",
    "outputId": "6677af21-82c1-41e5-b83e-014c04bee876"
   },
   "outputs": [],
   "source": [
    "class FakeNewsPredictor:\n",
    "    \"\"\"Classe pour les prÃ©dictions en temps rÃ©el\"\"\"\n",
    "\n",
    "    def __init__(self, model, tokenizer, image_transform, device):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.image_transform = image_transform\n",
    "        self.device = device\n",
    "        self.model.eval()\n",
    "\n",
    "        self.label_mapping = {0: \"Fake News\", 1: \"Real News\"}\n",
    "        self.confidence_levels = {\n",
    "            0: \"Faible (70-80%)\",\n",
    "            1: \"Moyenne (80-90%)\",\n",
    "            2: \"Moyenne (80-90%)\",\n",
    "            3: \"Ã‰levÃ©e (90%+)\"\n",
    "        }\n",
    "\n",
    "    def predict(self, title, text=\"\", image_path=None):\n",
    "        \"\"\"PrÃ©diction sur un article\"\"\"\n",
    "        # PrÃ©paration du texte\n",
    "        has_text = 1 if text and len(text.strip()) >= 50 else 0\n",
    "        combined_text = f\"{title} [SEP] {text}\" if has_text else title\n",
    "\n",
    "        # Tokenisation\n",
    "        encoding = self.tokenizer(\n",
    "            combined_text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # PrÃ©paration de l'image\n",
    "        image_tensor = torch.zeros(1, 3, 224, 224)\n",
    "        has_image = 0\n",
    "\n",
    "        if image_path and os.path.exists(image_path):\n",
    "            try:\n",
    "                image = Image.open(image_path).convert('RGB')\n",
    "                image_tensor = self.image_transform(image).unsqueeze(0)\n",
    "                has_image = 1\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur chargement image: {e}\")\n",
    "\n",
    "        # DÃ©placement vers GPU\n",
    "        input_ids = encoding['input_ids'].to(self.device)\n",
    "        attention_mask = encoding['attention_mask'].to(self.device)\n",
    "        image_tensor = image_tensor.to(self.device)\n",
    "        has_text_tensor = torch.tensor([has_text], dtype=torch.float).to(self.device)\n",
    "        has_image_tensor = torch.tensor([has_image], dtype=torch.float).to(self.device)\n",
    "\n",
    "        # PrÃ©diction\n",
    "        with torch.no_grad():\n",
    "            outputs, confidences = self.model(\n",
    "                input_ids, attention_mask, image_tensor,\n",
    "                has_text_tensor, has_image_tensor,\n",
    "                return_confidence=True\n",
    "            )\n",
    "\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            prediction = predicted.item()\n",
    "            confidence = confidences[0]\n",
    "            prob_fake = probabilities[0][0].item()\n",
    "            prob_real = probabilities[0][1].item()\n",
    "\n",
    "        # DÃ©termination du type de modalitÃ©\n",
    "        if has_text and has_image:\n",
    "            modality_type = 3\n",
    "        elif has_text:\n",
    "            modality_type = 2\n",
    "        elif has_image:\n",
    "            modality_type = 1\n",
    "        else:\n",
    "            modality_type = 0\n",
    "\n",
    "        return {\n",
    "            'prediction': self.label_mapping[prediction],\n",
    "            'confidence': confidence,\n",
    "            'confidence_level': self.confidence_levels[modality_type],\n",
    "            'probabilities': {\n",
    "                'fake': prob_fake,\n",
    "                'real': prob_real\n",
    "            },\n",
    "            'modality_type': modality_type,\n",
    "            'has_text': bool(has_text),\n",
    "            'has_image': bool(has_image)\n",
    "        }\n",
    "\n",
    "# Initialisation du prÃ©dicteur\n",
    "predictor = FakeNewsPredictor(model, tokenizer, image_transform, device)\n",
    "print(\"âœ… PrÃ©dicteur initialisÃ©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 474,
     "status": "ok",
     "timestamp": 1753900393147,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "gRlSDlYLf0DS",
    "outputId": "0f86474a-e267-4f0c-8fb3-0c1e8a222fed"
   },
   "outputs": [],
   "source": [
    "def test_prediction():\n",
    "    print(\"\\nðŸŽ¯ TESTS MULTIMODALITÃ‰S\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # ========= TITRE SEUL =========\n",
    "    print(\"\\nðŸŸ© TITRE SEUL\")\n",
    "    examples_title_only = [\n",
    "        \"Aliens seen landing on the White House lawn\",\n",
    "        \"Global economy shows strong recovery signs\"\n",
    "    ]\n",
    "    for i, title in enumerate(examples_title_only, 1):\n",
    "        result = predictor.predict(title)\n",
    "        print(f\"\\nðŸ”¹ Exemple {i}\")\n",
    "        print(f\"   Titre: {title}\")\n",
    "        print(f\"   PrÃ©diction: {result['prediction']} | Confiance: {result['confidence']:.3f} ({result['confidence_level']})\")\n",
    "        print(f\"   âž¤ ProbabilitÃ©s: Fake={result['probabilities']['fake']:.3f}, Real={result['probabilities']['real']:.3f}\")\n",
    "\n",
    "    # ========= TITRE + TEXTE =========\n",
    "    print(\"\\nðŸŸ¨ TITRE + TEXTE\")\n",
    "    examples_title_text = [\n",
    "        (\n",
    "            \"Vaccine proves 100% effective in new trial\",\n",
    "            \"A new trial conducted in Germany has proven that the vaccine is 100% effective across all age groups.\"\n",
    "        ),\n",
    "        (\n",
    "            \"NASA to build base on the moon by 2030\",\n",
    "            \"NASA announced plans to build a permanent research station on the moon within the next decade.\"\n",
    "        )\n",
    "    ]\n",
    "    for i, (title, text) in enumerate(examples_title_text, 1):\n",
    "        result = predictor.predict(title, text)\n",
    "        print(f\"\\nðŸ”¹ Exemple {i}\")\n",
    "        print(f\"   Titre: {title}\")\n",
    "        print(f\"   Texte: {text[:100]}...\")\n",
    "        print(f\"   PrÃ©diction: {result['prediction']} | Confiance: {result['confidence']:.3f} ({result['confidence_level']})\")\n",
    "        print(f\"   âž¤ ProbabilitÃ©s: Fake={result['probabilities']['fake']:.3f}, Real={result['probabilities']['real']:.3f}\")\n",
    "\n",
    "    # ========= TITRE + IMAGE =========\n",
    "    print(\"\\nðŸŸ¦ TITRE + IMAGE\")\n",
    "    examples_title_image = [\n",
    "        (\n",
    "            \"President caught doing something shocking\",\n",
    "            \"/content/image_final_ancien/ebb2b165f3ba33aabebaf416a7f2bb4b.jpg\"\n",
    "        ),\n",
    "        (\n",
    "            \"World Cup final ends in dramatic fashion\",\n",
    "            \"/content/image_final_ancien/f52a1871a7bd2e1de6b5f87be65a3ad6.jpg\"\n",
    "        )\n",
    "    ]\n",
    "    for i, (title, img_path) in enumerate(examples_title_image, 1):\n",
    "        result = predictor.predict(title, image_path=img_path)\n",
    "        print(f\"\\nðŸ”¹ Exemple {i}\")\n",
    "        print(f\"   Titre: {title}\")\n",
    "        print(f\"   Image: {img_path}\")\n",
    "        print(f\"   PrÃ©diction: {result['prediction']} | Confiance: {result['confidence']:.3f} ({result['confidence_level']})\")\n",
    "        print(f\"   âž¤ ProbabilitÃ©s: Fake={result['probabilities']['fake']:.3f}, Real={result['probabilities']['real']:.3f}\")\n",
    "\n",
    "    # ========= TITRE + TEXTE + IMAGE =========\n",
    "    print(\"\\nðŸŸ¥ TITRE + TEXTE + IMAGE\")\n",
    "    examples_full = [\n",
    "        (\n",
    "            \"Anti-Trump Super PAC Launches Pre-Debate Video Featuring Hofstra Students\",\n",
    "            \"An anti-Donald Trump super PAC is going on the offensive ahead of the first presidential debate...\",\n",
    "            \"/content/image_final_ancien/ebb2b165f3ba33aabebaf416a7f2bb4b.jpg\"\n",
    "        ),\n",
    "        (\n",
    "            \"Scientists celebrate successful Mars landing\",\n",
    "            \"NASA scientists cheered as the latest Mars lander touched down safely, confirming decades of planning.\",\n",
    "            \"/content/image_final_ancien/f52a1871a7bd2e1de6b5f87be65a3ad6.jpg\"\n",
    "        )\n",
    "    ]\n",
    "    for i, (title, text, img_path) in enumerate(examples_full, 1):\n",
    "        result = predictor.predict(title, text, img_path)\n",
    "        print(f\"\\nðŸ”¹ Exemple {i}\")\n",
    "        print(f\"   Titre: {title}\")\n",
    "        print(f\"   Texte: {text[:100]}...\")\n",
    "        print(f\"   Image: {img_path}\")\n",
    "        print(f\"   PrÃ©diction: {result['prediction']} | Confiance: {result['confidence']:.3f} ({result['confidence_level']})\")\n",
    "        print(f\"   âž¤ ProbabilitÃ©s: Fake={result['probabilities']['fake']:.3f}, Real={result['probabilities']['real']:.3f}\")\n",
    "\n",
    "    print(\"\\nâœ… Tous les tests de prÃ©diction sont terminÃ©s.\")\n",
    "\n",
    "# â–¶ï¸ Appel de la fonction\n",
    "test_prediction()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmZFzSbM3iGX"
   },
   "source": [
    "# ðŸ’¾ 4.6. SAUVEGARDE ET EXPORT DU MODÃˆLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1753900440580,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "stdeSP5T3iGX",
    "outputId": "80113490-ee98-4410-ca97-5bf88af9bbed"
   },
   "outputs": [],
   "source": [
    "print(\"\\nðŸ’¾ SAUVEGARDE ET EXPORT DU MODÃˆLE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Sauvegarde des rÃ©sultats finaux\n",
    "final_results = {\n",
    "    'model_info': {\n",
    "        'architecture': 'MultimodalFakeNewsDetector',\n",
    "        'bert_model': 'bert-base-uncased',\n",
    "        'cnn_model': 'resnet18',\n",
    "        'total_parameters': total_params,\n",
    "        'trainable_parameters': trainable_params\n",
    "    },\n",
    "    'training_config': config,\n",
    "    'final_metrics': {\n",
    "        'test_accuracy': float(accuracy),\n",
    "        'test_f1_score': float(f1),\n",
    "        'average_confidence': float(avg_confidence),\n",
    "        'best_val_accuracy': float(best_val_accuracy)\n",
    "    },\n",
    "    'modality_performance': {},\n",
    "    'training_history': {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies\n",
    "    }\n",
    "}\n",
    "\n",
    "# Ajouter les performances par modalitÃ©\n",
    "for modality, stats in modality_stats.items():\n",
    "    if stats['total'] > 0:\n",
    "        final_results['modality_performance'][modality_names[modality]] = {\n",
    "            'accuracy': float(stats['correct'] / stats['total']),\n",
    "            'samples': stats['total']\n",
    "        }\n",
    "\n",
    "# Sauvegarde JSON\n",
    "with open('final_results.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "\n",
    "# Sauvegarde du tokenizer\n",
    "tokenizer.save_pretrained('saved_tokenizer')\n",
    "\n",
    "# Sauvegarde des transformations d'images\n",
    "with open('image_transform.pkl', 'wb') as f:\n",
    "    pickle.dump(image_transform, f)\n",
    "\n",
    "print(\"âœ… RÃ©sultats finaux sauvegardÃ©s: final_results.json\")\n",
    "print(\"âœ… Tokenizer sauvegardÃ©: saved_tokenizer/\")\n",
    "print(\"âœ… Transformations d'images sauvegardÃ©es: image_transform.pkl\")\n",
    "print(f\"âœ… Meilleur modÃ¨le disponible: {config['best_model_path']}\")\n",
    "\n",
    "print(f\"\\nðŸŽ‰ PIPELINE DE MODÃ‰LISATION TERMINÃ‰ AVEC SUCCÃˆS!\")\n",
    "print(f\"ðŸ“Š PrÃ©cision finale: {accuracy:.4f}\")\n",
    "print(f\"ðŸ“Š F1-Score: {f1:.4f}\")\n",
    "print(f\"ðŸ“Š Confiance moyenne: {avg_confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "executionInfo": {
     "elapsed": 156,
     "status": "ok",
     "timestamp": 1753900450912,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "-spXuipfjHOR",
    "outputId": "446a621c-3f7d-4d39-c133-fee2fa0a509a"
   },
   "outputs": [],
   "source": [
    "print(\"\\nðŸ’¾ SAUVEGARDE ET EXPORT DU MODÃˆLE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Sauvegarde des rÃ©sultats finaux\n",
    "final_results = {\n",
    "    'model_info': {\n",
    "        'architecture': 'MultimodalFakeNewsDetector',\n",
    "        'bert_model': 'bert-base-uncased',\n",
    "        'cnn_model': 'resnet18',\n",
    "        'total_parameters': total_params,\n",
    "        'trainable_parameters': trainable_params\n",
    "    },\n",
    "    'training_config': config,\n",
    "    'final_metrics': {\n",
    "        'test_accuracy': float(accuracy),\n",
    "        'test_f1_score': float(f1),\n",
    "        'average_confidence': float(avg_confidence),\n",
    "        'best_val_accuracy': float(best_val_accuracy)\n",
    "    },\n",
    "    'modality_performance': {},\n",
    "    'training_history': {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies\n",
    "    }\n",
    "}\n",
    "\n",
    "# Ajouter les performances par modalitÃ©\n",
    "for modality, stats in modality_stats.items():\n",
    "    if stats['total'] > 0:\n",
    "        final_results['modality_performance'][modality_names[modality]] = {\n",
    "            'accuracy': float(stats['correct'] / stats['total']),\n",
    "            'samples': stats['total']\n",
    "        }\n",
    "\n",
    "# Sauvegarde JSON\n",
    "with open('final_results.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "\n",
    "# Sauvegarde du tokenizer\n",
    "tokenizer.save_pretrained('saved_tokenizer')\n",
    "\n",
    "# Sauvegarde des transformations d'images\n",
    "with open('image_transform.pkl', 'wb') as f:\n",
    "    pickle.dump(image_transform, f)\n",
    "\n",
    "print(\"âœ… RÃ©sultats finaux sauvegardÃ©s: final_results.json\")\n",
    "print(\"âœ… Tokenizer sauvegardÃ©: saved_tokenizer/\")\n",
    "print(\"âœ… Transformations d'images sauvegardÃ©es: image_transform.pkl\")\n",
    "print(f\"âœ… Meilleur modÃ¨le disponible: {config['best_model_path']}\")\n",
    "\n",
    "# ðŸ“¦ Compression du tokenizer en .zip pour tÃ©lÃ©chargement\n",
    "!zip -rq saved_tokenizer.zip saved_tokenizer\n",
    "\n",
    "# ðŸ’¾ TÃ©lÃ©chargement des fichiers vers le PC\n",
    "files.download(\"final_results.json\")\n",
    "files.download(\"image_transform.pkl\")\n",
    "files.download(\"saved_tokenizer.zip\")\n",
    "files.download(config[\"best_model_path\"])  # \"best_multimodal_model.pth\"\n",
    "\n",
    "print(f\"\\nðŸŽ‰ PIPELINE DE MODÃ‰LISATION TERMINÃ‰ AVEC SUCCÃˆS!\")\n",
    "print(f\"ðŸ“Š PrÃ©cision finale: {accuracy:.4f}\")\n",
    "print(f\"ðŸ“Š F1-Score: {f1:.4f}\")\n",
    "print(f\"ðŸ“Š Confiance moyenne: {avg_confidence:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1753901183427,
     "user": {
      "displayName": "skander gacem",
      "userId": "06007509127256361676"
     },
     "user_tz": -120
    },
    "id": "SOD3WZcPp2_5",
    "outputId": "0abce508-cd00-4ce0-c0a2-2eb4f5495242"
   },
   "outputs": [],
   "source": [
    "files.download(config[\"best_model_path\"])  # \"best_multimodal_model.pth\"\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1QgH9-JGvUDANYpRfxPr0Bn4IdrgoU670",
     "timestamp": 1754499596452
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
